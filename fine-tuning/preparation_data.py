"""
Script 2 - PrÃ©paration du Dataset de Fine-tuning
Objectif: CrÃ©er les paires (input â†’ output) pour entraÃ®ner le modÃ¨le
          Ã  partir des corrections manuelles
"""

import pandas as pd
import json
from pathlib import Path
import re
import random

# ==================== CONFIGURATION ====================

racine = Path(r"C:\Users\ZAID\OneDrive\Documents\3eme_gds\DL\DeepLearning_1")
dataset_complet = racine / "dataset_complet.csv"
finetuning_dir = racine / "finetuning_data"

# Fichiers d'entrÃ©e
template_correction_file = finetuning_dir / "01_llama_non_prouvees_TEMPLATE_CORRECTION.json"

# Fichiers de sortie
dataset_finetuning = finetuning_dir / "02_dataset_finetuning.jsonl"
dataset_train = finetuning_dir / "02_dataset_train.jsonl"
dataset_validation = finetuning_dir / "02_dataset_validation.jsonl"
rapport_dataset = finetuning_dir / "02_rapport_dataset.txt"

SYSTEM_PROMPT = (
    "Tu es un assistant mÃ©dical expert. "
    "Tu rÃ©ponds UNIQUEMENT avec des informations scientifiquement prouvÃ©es. "
    "Tu cites toujours tes sources (HAS, OMS, PubMed, Ã©tudes scientifiques). "
    "Tu es empathique et rassurant tout en restant prÃ©cis et factuel."
)

MODELE_LLAMA = "meta-llama/llama-4-scout-17b-16e-instruct"

# ==================== UTILITAIRES ROBUSTES ====================

def safe_int_from_id(value, fallback=None):
    """
    Convertit id_cas en entier si possible.
    Ex: 'CAS_004' -> 4, '18' -> 18, sinon fallback.
    """
    if value is None or pd.isna(value):
        return fallback
    s = str(value).strip()
    if s.isdigit():
        return int(s)
    m = re.search(r"\d+", s)
    if m:
        return int(m.group())
    return fallback

def safe_text(x, default="N/A"):
    """Retourne un texte propre mÃªme si NaN."""
    if x is None or pd.isna(x):
        return default
    return str(x)

# ==================== VÃ‰RIFICATION ====================

print("="*70)
print("ğŸ“‚ PRÃ‰PARATION DU DATASET DE FINE-TUNING")
print("="*70)

if not template_correction_file.exists():
    print(f"\nâŒ ERREUR: Fichier de corrections introuvable!")
    print(f"   Attendu: {template_correction_file}")
    print(f"\nğŸ“‹ Ã‰TAPES Ã€ SUIVRE:")
    print("   1. ExÃ©cutez d'abord le Script 1 (extraction)")
    print("   2. Remplissez les corrections manuellement dans le JSON")
    print("   3. Relancez ce script")
    raise SystemExit(1)

print("âœ… Fichier de corrections trouvÃ©")

# ==================== CHARGEMENT DES CORRECTIONS ====================

print("\n" + "="*70)
print("ğŸ“¥ CHARGEMENT DES CORRECTIONS")
print("="*70)

with open(template_correction_file, 'r', encoding='utf-8') as f:
    corrections = json.load(f)

print(f"âœ… {len(corrections)} cas chargÃ©s")

# VÃ©rifier si les corrections ont Ã©tÃ© faites
nb_corriges = 0
nb_non_corriges = 0

for corr in corrections:
    texte_corrige = corr.get('reponse_corrigee', {}).get('texte', '')
    if "Ã€ REMPLIR MANUELLEMENT" not in safe_text(texte_corrige, ""):
        nb_corriges += 1
    else:
        nb_non_corriges += 1

print(f"\nğŸ“Š Ã‰tat des corrections:")
print(f"   âœ… CorrigÃ©s: {nb_corriges}")
print(f"   â³ Ã€ corriger: {nb_non_corriges}")

if nb_corriges == 0:
    print(f"\nâš ï¸  ATTENTION: Aucune correction n'a Ã©tÃ© faite!")
    print(f"   Veuillez d'abord corriger les cas dans:")
    print(f"   {template_correction_file}")
    print(f"\n   Cherchez 'Ã€ REMPLIR MANUELLEMENT' et remplacez par votre correction")
    raise SystemExit(1)

# ==================== CRÃ‰ATION DATASET FINE-TUNING ====================

print("\n" + "="*70)
print("ğŸ”§ CRÃ‰ATION DU DATASET DE FINE-TUNING")
print("="*70)

dataset_entries = []

for corr in corrections:
    texte_corrige = corr.get('reponse_corrigee', {}).get('texte', '')
    if "Ã€ REMPLIR MANUELLEMENT" in safe_text(texte_corrige, ""):
        continue

    entry = {
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": safe_text(corr.get('description_cas'))},
            {"role": "assistant", "content": safe_text(texte_corrige)}
        ],
        "metadata": {
            # âœ… cas_id peut Ãªtre int ou string selon ton JSON; on le garde tel quel + on sÃ©curise
            "cas_id": corr.get("cas_id"),
            "cas_id_original": corr.get("cas_id_original", None),
            "categorie": corr.get('categorie', 'N/A'),
            "sources": corr.get('reponse_corrigee', {}).get('sources_ajoutees', []),
            "type_correction": "non_prouvee_vers_prouvee"
        }
    }

    dataset_entries.append(entry)

print(f"âœ… {len(dataset_entries)} paires crÃ©Ã©es (input â†’ output corrigÃ©)")

# ==================== AJOUT DES EXEMPLES POSITIFS ====================

print("\n" + "="*70)
print("â• AJOUT DES EXEMPLES POSITIFS (rÃ©ponses dÃ©jÃ  bonnes)")
print("="*70)

df = pd.read_csv(dataset_complet, encoding='utf-8-sig')
llama = df[df['modele'] == MODELE_LLAMA].copy()

def normaliser_verdict(verdict):
    if pd.isna(verdict):
        return None
    v = str(verdict).lower().strip()
    return v.replace('Ã©', 'e').replace('Ã¨', 'e').replace('Ãª', 'e').replace('_', ' ')

def est_prouvee(verdict):
    v = normaliser_verdict(verdict)
    if v is None:
        return False
    # prouvee/validee/valide mais pas "non ..."
    return any(mot in v for mot in ['prouvee', 'prouve', 'validee', 'valide']) and 'non' not in v

llama['est_prouvee'] = llama['verdict_scientifique'].apply(est_prouvee)
prouvees = llama[llama['est_prouvee']].copy()

print(f"ğŸ“Š RÃ©ponses prouvÃ©es de Llama: {len(prouvees)}")

nb_exemples = min(30, len(prouvees))
if nb_exemples == 0:
    print("âš ï¸ Aucun exemple positif trouvÃ© (aucune rÃ©ponse prouvÃ©e dÃ©tectÃ©e).")
else:
    prouvees_sample = prouvees.sample(n=nb_exemples, random_state=42)
    print(f"âœ… Ajout de {nb_exemples} exemples positifs")

    for idx, row in prouvees_sample.iterrows():
        id_cas_val = row.get('id_cas', None)
        cas_id_int = safe_int_from_id(id_cas_val, fallback=None)

        entry = {
            "messages": [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": safe_text(row.get('description'))},
                {"role": "assistant", "content": safe_text(row.get('reponse_texte'))}
            ],
            "metadata": {
                # âœ… correction du bug ici (plus de int('CAS_004'))
                "cas_id": cas_id_int,
                "cas_id_original": None if pd.isna(id_cas_val) else str(id_cas_val),
                "categorie": safe_text(row.get('categorie')),
                "type_correction": "exemple_positif"
            }
        }

        dataset_entries.append(entry)

print(f"\nğŸ“Š Dataset total: {len(dataset_entries)} exemples")
print(f"   â€¢ Corrections (non prouvÃ©e â†’ prouvÃ©e): {nb_corriges}")
print(f"   â€¢ Exemples positifs (dÃ©jÃ  prouvÃ©es): {nb_exemples}")

# ==================== SPLIT TRAIN / VALIDATION ====================

print("\n" + "="*70)
print("âœ‚ï¸  SPLIT TRAIN / VALIDATION")
print("="*70)

random.seed(42)
random.shuffle(dataset_entries)

split_idx = int(len(dataset_entries) * 0.8)
train_data = dataset_entries[:split_idx]
val_data = dataset_entries[split_idx:]

print(f"âœ… Train: {len(train_data)} exemples (80%)")
print(f"âœ… Validation: {len(val_data)} exemples (20%)")

# ==================== SAUVEGARDE ====================

print("\n" + "="*70)
print("ğŸ’¾ SAUVEGARDE DES DATASETS")
print("="*70)

def save_jsonl(data, filepath):
    with open(filepath, 'w', encoding='utf-8') as f:
        for entry in data:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')

save_jsonl(dataset_entries, dataset_finetuning)
print(f"âœ… Dataset complet: {dataset_finetuning.name}")

save_jsonl(train_data, dataset_train)
print(f"âœ… Dataset train: {dataset_train.name}")

save_jsonl(val_data, dataset_validation)
print(f"âœ… Dataset validation: {dataset_validation.name}")

# ==================== RAPPORT ====================

rapport = []
rapport.append("="*70)
rapport.append("RAPPORT DU DATASET DE FINE-TUNING")
rapport.append("="*70)
rapport.append("")
rapport.append("ğŸ“Š Statistiques:")
rapport.append(f"   â€¢ Total exemples: {len(dataset_entries)}")
rapport.append(f"   â€¢ Corrections (non prouvÃ©e â†’ prouvÃ©e): {nb_corriges}")
rapport.append(f"   â€¢ Exemples positifs: {nb_exemples}")
rapport.append("")
rapport.append("âœ‚ï¸  Split:")
rapport.append(f"   â€¢ Train: {len(train_data)} exemples (80%)")
rapport.append(f"   â€¢ Validation: {len(val_data)} exemples (20%)")
rapport.append("")
rapport.append("ğŸ“ Fichiers crÃ©Ã©s:")
rapport.append(f"   â€¢ {dataset_finetuning.name}")
rapport.append(f"   â€¢ {dataset_train.name}")
rapport.append(f"   â€¢ {dataset_validation.name}")
rapport.append("")
rapport.append("ğŸ¯ Objectifs du fine-tuning:")
rapport.append("   1. Ã‰liminer les rÃ©ponses non prouvÃ©es")
rapport.append("   2. Toujours citer des sources scientifiques")
rapport.append("   3. Maintenir l'empathie et le ton appropriÃ©")
rapport.append("")
rapport.append("ğŸ“‹ Format du dataset:")
rapport.append("   â€¢ Format: JSONL (JSON Lines)")
rapport.append("   â€¢ Structure: messages conversationnels")
rapport.append("   â€¢ SystÃ¨me prompt: instructions pour validation scientifique")
rapport.append("")
rapport.append("ğŸ”§ Prochaine Ã©tape:")
rapport.append("   Script 3 - Configuration et lancement du fine-tuning")
rapport.append("")

with open(rapport_dataset, 'w', encoding='utf-8') as f:
    f.write('\n'.join(rapport))

print(f"âœ… Rapport: {rapport_dataset.name}")

# ==================== APERÃ‡U ====================

print("\n" + "="*70)
print("ğŸ‘€ APERÃ‡U DU DATASET")
print("="*70)

if len(train_data) > 0:
    exemple = train_data[0]
    print("\nğŸ“‹ Exemple d'entrÃ©e de dataset:")
    print("-" * 70)
    print(f"SYSTÃˆME: {exemple['messages'][0]['content'][:100]}...")
    print(f"\nUSER: {exemple['messages'][1]['content'][:150]}...")
    print(f"\nASSISTANT: {exemple['messages'][2]['content'][:200]}...")
    print("-" * 70)

# ==================== INSTRUCTIONS FINALES ====================

print("\n" + "="*70)
print("ğŸ“‹ PROCHAINES Ã‰TAPES")
print("="*70)

print(f"""
âœ… Dataset de fine-tuning prÃªt!

ğŸ“‚ Fichiers crÃ©Ã©s dans: {finetuning_dir}
   â€¢ {dataset_train.name} ({len(train_data)} exemples)
   â€¢ {dataset_validation.name} ({len(val_data)} exemples)

ğŸ¯ Ce dataset permettra Ã  Llama d'apprendre Ã :
   1. âœ… Ne jamais gÃ©nÃ©rer de rÃ©ponses non prouvÃ©es
   2. âœ… Toujours valider scientifiquement ses rÃ©ponses
   3. âœ… Citer des sources fiables
   4. âœ… Maintenir un ton empathique

ğŸš€ Prochaine Ã©tape: Script 3
   â†’ Configuration du fine-tuning (LoRA/QLoRA)
   â†’ Choix des hyperparamÃ¨tres
   â†’ Lancement de l'entraÃ®nement

ğŸ’¡ Conseil:
   Avant de fine-tuner, vÃ©rifiez que toutes vos corrections
   dans le fichier JSON sont de qualitÃ© et citent des sources
   scientifiques fiables!
""")

print("\n" + "="*70)
print("âœ… PRÃ‰PARATION DU DATASET TERMINÃ‰E")
print("="*70)
