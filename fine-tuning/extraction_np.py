"""
Script 1 - Extraction des 7 RÃ©ponses NON PROUVÃ‰ES de Llama
Objectif: Identifier et analyser ces cas pour comprendre pourquoi
          le modÃ¨le a gÃ©nÃ©rÃ© des rÃ©ponses non validÃ©es
"""

import pandas as pd
from pathlib import Path
import json
import re

# ==================== CONFIGURATION ====================

racine = Path(r"C:\Users\ZAID\OneDrive\Documents\3eme_gds\DL\DeepLearning_1")
dataset_complet = racine / "dataset_complet.csv"
finetuning_dir = racine / "finetuning_data"
finetuning_dir.mkdir(parents=True, exist_ok=True)

# Fichiers de sortie
extraction_file = finetuning_dir / "01_llama_non_prouvees_EXTRACTION.csv"
analyse_file = finetuning_dir / "01_llama_non_prouvees_ANALYSE.txt"
template_correction_file = finetuning_dir / "01_llama_non_prouvees_TEMPLATE_CORRECTION.json"

# ==================== DÃ‰TECTION VERDICTS ====================

def normaliser_verdict(verdict):
    if pd.isna(verdict):
        return None
    v = str(verdict).lower().strip()
    v = v.replace('Ã©', 'e').replace('Ã¨', 'e').replace('Ãª', 'e').replace('_', ' ')
    return v

def est_non_prouvee(verdict):
    v = normaliser_verdict(verdict)
    if v is None:
        return False
    return any(mot in v for mot in ['non prouvee', 'non prouve', 'non validee'])

# ==================== UTILITAIRES ROBUSTES ====================

def safe_float(x, default=0.0):
    """Convertit en float sans planter si NaN / vide / string."""
    try:
        if pd.isna(x):
            return default
        return float(x)
    except Exception:
        return default

def safe_int_from_id(value, fallback):
    """
    Convertit id_cas en entier si possible.
    Exemple: 'CAS_018' -> 18, '18' -> 18, sinon fallback.
    """
    if pd.isna(value):
        return fallback
    s = str(value).strip()
    # Si c'est dÃ©jÃ  un nombre (ex: '18')
    if s.isdigit():
        return int(s)
    # Extraire le premier groupe de chiffres (ex: 'CAS_018' -> 018)
    m = re.search(r"\d+", s)
    if m:
        return int(m.group())
    return fallback

# ==================== CHARGEMENT ====================

print("="*70)
print("ðŸ“‚ EXTRACTION DES NON PROUVÃ‰ES DE LLAMA")
print("="*70)

df = pd.read_csv(dataset_complet, encoding='utf-8-sig')
print(f"âœ… Dataset chargÃ©: {len(df)} lignes")

# Filtrer Llama
modele_llama = "meta-llama/llama-4-scout-17b-16e-instruct"
llama = df[df['modele'] == modele_llama].copy()
print(f"âœ… RÃ©ponses Llama: {len(llama)}")

# ==================== EXTRACTION ====================

print("\n" + "="*70)
print("ðŸ” IDENTIFICATION DES NON PROUVÃ‰ES")
print("="*70)

# Identifier les non prouvÃ©es
llama['est_non_prouvee'] = llama['verdict_scientifique'].apply(est_non_prouvee)
non_prouvees = llama[llama['est_non_prouvee']].copy()

print(f"\nðŸš¨ Nombre de non prouvÃ©es trouvÃ©es: {len(non_prouvees)}")

if len(non_prouvees) == 0:
    print("\nâœ… Aucune non prouvÃ©e dÃ©tectÃ©e!")
    print("   VÃ©rifiez les verdicts manuellement si vous pensez qu'il devrait y en avoir.")
    raise SystemExit(0)

# ==================== ANALYSE DÃ‰TAILLÃ‰E ====================

print("\n" + "="*70)
print("ðŸ“‹ ANALYSE DÃ‰TAILLÃ‰E DE CHAQUE CAS")
print("="*70)

colonnes_importantes = [
    'id_cas', 'titre', 'description', 'categorie', 'objectif',
    'prompt', 'reponse_texte', 'verdict_scientifique', 'justification',
    'sources_utilisees', 'ton_dominant', 'credibilite_percue',
    'score_certitude', 'score_empathie', 'niveau_anxiete',
    'longueur_reponse', 'nb_mots'
]

# Garder seulement les colonnes qui existent
colonnes_existantes = [col for col in colonnes_importantes if col in non_prouvees.columns]
non_prouvees_export = non_prouvees[colonnes_existantes].copy()

# Ajouter un numÃ©ro d'ordre
non_prouvees_export.insert(0, 'numero', range(1, len(non_prouvees_export) + 1))

# Afficher chaque cas
rapport_analyse = []
rapport_analyse.append("="*70)
rapport_analyse.append("ANALYSE DES RÃ‰PONSES NON PROUVÃ‰ES DE LLAMA")
rapport_analyse.append("="*70)
rapport_analyse.append("")

for idx, row in non_prouvees_export.iterrows():
    num = row['numero']
    rapport_analyse.append(f"\n{'='*70}")
    rapport_analyse.append(f"CAS #{num}")
    rapport_analyse.append(f"{'='*70}")

    # Informations du cas
    if 'titre' in non_prouvees_export.columns:
        rapport_analyse.append(f"\nðŸ“‹ Titre: {row.get('titre', 'N/A')}")
    if 'categorie' in non_prouvees_export.columns:
        rapport_analyse.append(f"ðŸ“‚ CatÃ©gorie: {row.get('categorie', 'N/A')}")
    if 'objectif' in non_prouvees_export.columns:
        rapport_analyse.append(f"ðŸŽ¯ Objectif: {row.get('objectif', 'N/A')}")

    # Description du cas
    if 'description' in non_prouvees_export.columns:
        rapport_analyse.append(f"\nðŸ“ Description du cas:")
        rapport_analyse.append(f"{row.get('description', 'N/A')}")

    # RÃ©ponse de Llama
    if 'reponse_texte' in non_prouvees_export.columns:
        reponse = row.get('reponse_texte', '')
        reponse = '' if pd.isna(reponse) else str(reponse)
        rapport_analyse.append(f"\nðŸ¤– RÃ©ponse de Llama:")
        rapport_analyse.append(f"{reponse[:500]}...")
        rapport_analyse.append(f"   Longueur: {row.get('longueur_reponse', 'N/A')} caractÃ¨res")
        rapport_analyse.append(f"   Mots: {row.get('nb_mots', 'N/A')}")

    # Verdict et justification
    rapport_analyse.append(f"\nâŒ Verdict: {row.get('verdict_scientifique', 'N/A')}")
    if 'justification' in non_prouvees_export.columns and pd.notna(row.get('justification', None)):
        rapport_analyse.append(f"\nðŸ“– Justification:")
        rapport_analyse.append(f"{row.get('justification')}")

    if 'sources_utilisees' in non_prouvees_export.columns and pd.notna(row.get('sources_utilisees', None)):
        rapport_analyse.append(f"\nðŸ“š Sources utilisÃ©es:")
        rapport_analyse.append(f"{row.get('sources_utilisees')}")

    # Impact psychologique
    rapport_analyse.append(f"\nðŸ’­ Impact Psychologique:")
    if 'credibilite_percue' in non_prouvees_export.columns:
        rapport_analyse.append(f"   â€¢ CrÃ©dibilitÃ© perÃ§ue: {safe_float(row.get('credibilite_percue')):.2f}/10")
    if 'score_certitude' in non_prouvees_export.columns:
        rapport_analyse.append(f"   â€¢ Certitude: {safe_float(row.get('score_certitude')):.2f}/10")
    if 'score_empathie' in non_prouvees_export.columns:
        rapport_analyse.append(f"   â€¢ Empathie: {safe_float(row.get('score_empathie')):.2f}/10")
    if 'ton_dominant' in non_prouvees_export.columns:
        rapport_analyse.append(f"   â€¢ Ton dominant: {row.get('ton_dominant', 'N/A')}")
    if 'niveau_anxiete' in non_prouvees_export.columns:
        rapport_analyse.append(f"   â€¢ AnxiÃ©tÃ© induite: {row.get('niveau_anxiete', 'N/A')}")

    rapport_analyse.append("")
    rapport_analyse.append("ðŸ”§ ACTION REQUISE: Corriger cette rÃ©ponse manuellement")
    rapport_analyse.append("   â†’ Ajouter validation scientifique")
    rapport_analyse.append("   â†’ Citer sources fiables (HAS, OMS, PubMed)")
    rapport_analyse.append("")

    # Affichage console
    print(f"\n{'â”€'*70}")
    print(f"CAS #{num}: {row.get('titre', 'Sans titre')}")
    print(f"CatÃ©gorie: {row.get('categorie', 'N/A')}")
    print(f"CrÃ©dibilitÃ©: {safe_float(row.get('credibilite_percue')):.2f}/10")
    print(f"Longueur: {row.get('nb_mots', 0)} mots")

# ==================== CRÃ‰ATION TEMPLATE CORRECTION ====================

print("\n" + "="*70)
print("ðŸ“ CRÃ‰ATION DU TEMPLATE DE CORRECTION")
print("="*70)

template_corrections = []

for idx, row in non_prouvees_export.iterrows():
    cas_id_value = row.get('id_cas', None) if 'id_cas' in non_prouvees_export.columns else None
    cas_id_int = safe_int_from_id(cas_id_value, fallback=int(row['numero']))

    template = {
        # âœ… correction ici : plus de int('CAS_018')
        "cas_id": cas_id_int,
        # bonus: garder l'id original pour traÃ§abilitÃ©
        "cas_id_original": None if pd.isna(cas_id_value) else str(cas_id_value),

        "numero": int(row['numero']),
        "categorie": row.get('categorie', 'N/A'),
        "titre": row.get('titre', 'N/A'),
        "description_cas": row.get('description', 'N/A'),

        # RÃ©ponse actuelle (non prouvÃ©e)
        "reponse_actuelle": {
            "texte": row.get('reponse_texte', 'N/A'),
            "probleme": "Non prouvÃ©e scientifiquement",
            "justification_probleme": row.get('justification', 'N/A')
        },

        # Template pour la correction
        "reponse_corrigee": {
            "texte": "Ã€ REMPLIR MANUELLEMENT - RÃ©Ã©crire la rÃ©ponse avec validation scientifique",
            "sources_ajoutees": [
                "Ã€ AJOUTER - Source 1 (HAS, OMS, PubMed)",
                "Ã€ AJOUTER - Source 2",
                "Ã€ AJOUTER - Source 3"
            ],
            "modifications_effectuees": [
                "Ajout de validation scientifique",
                "Citation de sources fiables",
                "Reformulation pour plus de prÃ©cision"
            ]
        },

        # Infos supplÃ©mentaires
        "impact_psycho": {
            "credibilite": safe_float(row.get('credibilite_percue', 0)),
            "ton": row.get('ton_dominant', 'N/A'),
            "anxiete": row.get('niveau_anxiete', 'N/A')
        },

        "instructions_correction": [
            "1. Rechercher des sources scientifiques fiables (PubMed, HAS, OMS, Cochrane)",
            "2. VÃ©rifier la validitÃ© de l'information",
            "3. RÃ©Ã©crire la rÃ©ponse en citant les sources",
            "4. Conserver le ton empathique si prÃ©sent",
            "5. Ajouter les rÃ©fÃ©rences dans 'sources_ajoutees'"
        ]
    }

    template_corrections.append(template)

# ==================== SAUVEGARDE ====================

print("\n" + "="*70)
print("ðŸ’¾ SAUVEGARDE DES FICHIERS")
print("="*70)

# 1. CSV avec toutes les donnÃ©es
non_prouvees_export.to_csv(extraction_file, index=False, encoding='utf-8-sig')
print(f"âœ… CSV d'extraction: {extraction_file.name}")

# 2. Rapport d'analyse
with open(analyse_file, 'w', encoding='utf-8') as f:
    f.write('\n'.join(rapport_analyse))
print(f"âœ… Rapport d'analyse: {analyse_file.name}")

# 3. Template JSON pour corrections
with open(template_correction_file, 'w', encoding='utf-8') as f:
    json.dump(template_corrections, f, indent=2, ensure_ascii=False)
print(f"âœ… Template de correction: {template_correction_file.name}")

# ==================== STATISTIQUES ====================

print("\n" + "="*70)
print("ðŸ“Š STATISTIQUES DES NON PROUVÃ‰ES")
print("="*70)

if 'categorie' in non_prouvees_export.columns:
    print("\nðŸ“‚ RÃ©partition par catÃ©gorie:")
    cat_counts = non_prouvees_export['categorie'].value_counts()
    for cat, count in cat_counts.items():
        print(f"   â€¢ {cat}: {count} cas")

if 'credibilite_percue' in non_prouvees_export.columns:
    print(f"\nðŸ’¡ CrÃ©dibilitÃ© perÃ§ue:")
    print(f"   â€¢ Moyenne: {non_prouvees_export['credibilite_percue'].apply(safe_float).mean():.2f}/10")
    print(f"   â€¢ Min: {non_prouvees_export['credibilite_percue'].apply(safe_float).min():.2f}")
    print(f"   â€¢ Max: {non_prouvees_export['credibilite_percue'].apply(safe_float).max():.2f}")

    nb_credibles = (non_prouvees_export['credibilite_percue'].apply(safe_float) > 5).sum()
    print(f"   â€¢ Cas avec crÃ©dibilitÃ© > 5: {nb_credibles}")

if 'nb_mots' in non_prouvees_export.columns:
    print(f"\nðŸ“ Longueur des rÃ©ponses:")
    print(f"   â€¢ Moyenne: {non_prouvees_export['nb_mots'].mean():.0f} mots")
    print(f"   â€¢ Min: {non_prouvees_export['nb_mots'].min():.0f} mots")
    print(f"   â€¢ Max: {non_prouvees_export['nb_mots'].max():.0f} mots")

# ==================== INSTRUCTIONS FINALES ====================

print("\n" + "="*70)
print("ðŸ“‹ PROCHAINES Ã‰TAPES")
print("="*70)

print(f"""
âœ… 3 fichiers crÃ©Ã©s dans: {finetuning_dir}

1ï¸âƒ£ {extraction_file.name}
   â†’ Ouvrir avec Excel pour voir tous les dÃ©tails

2ï¸âƒ£ {analyse_file.name}
   â†’ Lire pour comprendre chaque cas

3ï¸âƒ£ {template_correction_file.name}
   â†’ Remplir manuellement les corrections

ðŸ“ COMMENT CORRIGER:

Pour chaque cas dans le fichier JSON:
1. Lire la description du cas
2. Lire la rÃ©ponse actuelle (non prouvÃ©e)
3. Rechercher des sources scientifiques:
   â€¢ PubMed: https://pubmed.ncbi.nlm.nih.gov/
   â€¢ HAS: https://www.has-sante.fr/
   â€¢ OMS: https://www.who.int/
4. RÃ©Ã©crire la rÃ©ponse avec validation scientifique
5. Ajouter les sources dans "sources_ajoutees"
6. Remplir "reponse_corrigee" > "texte"

Une fois les corrections terminÃ©es, passez au Script 2 pour crÃ©er
le dataset de fine-tuning!
""")

print("\n" + "="*70)
print("âœ… EXTRACTION TERMINÃ‰E")
print("="*70)
