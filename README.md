# ğŸ©ºğŸ§  FineMedâ€‘LLM â€” Plateforme dâ€™assistant mÃ©dical prudent (LLM fineâ€‘tunÃ©)
ğŸ§  Plateforme web pour interagir avec un **LLM fineâ€‘tunÃ©** afin de gÃ©nÃ©rer des rÃ©ponses mÃ©dicales **plus prudentes** et **plus sÃ»res** (sans diagnostic).

**FineMedâ€‘LLM** est un projet acadÃ©mique qui Ã©tudie les risques des LLMs en mÃ©decine (rÃ©ponses non validÃ©es mais convaincantes) et propose une **stratÃ©gie de mitigation** via **fineâ€‘tuning supervisÃ© (QLoRA)**.  
ğŸ‘‰ Le livrable applicatif de ce dÃ©pÃ´t est une **plateforme** (API Flask + interface) permettant de tester le **modÃ¨le fineâ€‘tunÃ©** sur des scÃ©narios mÃ©dicaux, avec une interaction simple et structurÃ©e. :contentReference[oaicite:0]{index=0} :contentReference[oaicite:1]{index=1}

---

## ğŸ¯ Objectif
DÃ©ployer un assistant mÃ©dical **expÃ©rimental** basÃ© sur un modÃ¨le **fineâ€‘tunÃ©** pour :
- rÃ©duire les rÃ©ponses **non prouvÃ©es** et les formulations Ã  risque (fausse certitude, ton alarmiste/rassurant inadaptÃ©),
- renforcer la **prudence** (incertitude explicite, recommandations nuancÃ©es, orientation vers consultation),
- fournir une interface claire pour tester des cas sensibles (anxiogÃ¨nes / psychologiques). :contentReference[oaicite:2]{index=2} :contentReference[oaicite:3]{index=3}

---

## ğŸš€ FonctionnalitÃ©s principales
- ğŸ¤– **GÃ©nÃ©ration de rÃ©ponses mÃ©dicales** via le **modÃ¨le fineâ€‘tunÃ©** : `Qwen2.5â€‘1.5Bâ€‘Instruct (QLoRA)`
- ğŸŒ **Interface web** pour :
  - saisir un cas clinique librement,
  - tester des **scÃ©narios prÃ©dÃ©finis**,
  - afficher une rÃ©ponse structurÃ©e (prudence + limites de lâ€™IA)
- ğŸ§© **Comportement â€œassistant mÃ©dical prudentâ€** (rappels explicites : pas de diagnostic, conseils gÃ©nÃ©raux, orientation si nÃ©cessaire)
- ğŸ§ª (Contexte projet) Pipeline expÃ©rimental : dataset simulÃ© â†’ gÃ©nÃ©ration multiâ€‘modÃ¨les â†’ Ã©valuation scientifique (RAG) â†’ analyse psycho â†’ extraction des rÃ©ponses Ã  risque â†’ fineâ€‘tuning. :contentReference[oaicite:4]{index=4} :contentReference[oaicite:5]{index=5}

---

## ğŸ§° Technologies utilisÃ©es

| CatÃ©gorie | Technologies |
|---|---|
| Langage principal | Python |
| API / Backend | Flask |
| LLM fineâ€‘tunÃ© (dÃ©ployÃ©) | **Qwen2.5â€‘1.5Bâ€‘Instruct** |
| Fineâ€‘tuning | **LoRA / QLoRA (4â€‘bits)**, **Unsloth** |
| NLP (analyse projet) | VADER, TextBlob (selon pipeline dâ€™analyse) |
| RAG (analyse projet) | pypdf (PDFâ†’txt), sentenceâ€‘transformers, FAISS |
| Sources mÃ©dicales (analyse projet) | HAS, OMS :contentReference[oaicite:6]{index=6} :contentReference[oaicite:7]{index=7}

---

## ğŸ§¬ DonnÃ©es utilisÃ©es (contexte du projet)
- **Jeu de cas** : **100 cas cliniques simulÃ©s** construits Ã  partir de questions rÃ©alistes issues de *HealthCareMagicâ€‘100kâ€‘en* (utilisÃ© uniquement comme rÃ©servoir de questions), rÃ©partis en 4 catÃ©gories :  
  **Simples | Complexes | AnxiogÃ¨nes | Psychologiques**. :contentReference[oaicite:8]{index=8}
- **Dataset de fineâ€‘tuning interne** :
  - extraction de rÃ©ponses Ã  risque (non prouvÃ©es / dangereuses),
  - crÃ©ation de **paires pÃ©dagogiques** (rÃ©ponse problÃ©matique â†’ rÃ©ponse corrigÃ©e prudente),
  - format conversationnel Instruct, split train/val (80/20). :contentReference[oaicite:9]{index=9} :contentReference[oaicite:10]{index=10}

---

## ğŸ§  ModÃ¨le fineâ€‘tunÃ© (celui utilisÃ© dans la plateforme)
- **Base** : `Qwen2.5â€‘1.5Bâ€‘Instruct`
- **MÃ©thode** : **QLoRA** (quantification 4 bits + adaptateurs LoRA)
- **Objectif** : alignement comportemental (prudence, incertitude, orientation), pas â€œdiagnostic automatiqueâ€
- **Ã‰valuation avant/aprÃ¨s** : amÃ©lioration quantitative rapportÃ©e (ex. score base 14/30 â†’ 16/30, +6,7%). :contentReference[oaicite:11]{index=11}

---

## âš™ï¸ Installation
> Les commandes exactes peuvent dÃ©pendre de votre arborescence (`backend/`, `frontend/`, etc.).  
> Le minimum requis est un environnement Python + `requirements.txt`.

CrÃ©er un environnement virtuel et installer les dÃ©pendances :
```bash
python -m venv .venv && source .venv/bin/activate   # Windows : .venv\Scripts\activate
pip install -r requirements.txt
```
---

## ğŸ‘©â€ğŸ’» Contributeurs
- [Nada Benchaou](https://github.com/BNAD-A)
- [Meriam El Kehaili](https://github.com/MeriamElk) 
- [Zayd Ladid](https://github.com/zaydld)
- [Anass Oumam](https://github.com/spaycey)



---



## âš ï¸ Avertissement

FineMed-LLM est un projet acadÃ©mique Ã  visÃ©e de recherche.
Il ne constitue pas un dispositif mÃ©dical et ne remplace pas une consultation clinique.
Les rÃ©ponses gÃ©nÃ©rÃ©es doivent Ãªtre validÃ©es par un professionnel de santÃ©.
Ce projet est distribuÃ© sous la licence **MIT**.  
Vous Ãªtes libre de le rÃ©utiliser, le modifier et le distribuer avec attribution.


---
