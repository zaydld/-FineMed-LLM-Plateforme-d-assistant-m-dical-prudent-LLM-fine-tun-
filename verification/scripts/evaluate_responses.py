import csv
import json
import time
import re
import unicodedata
from datetime import datetime
from pathlib import Path

from rag_query import get_rag
from judge_provider import judge_scientific

BASE_DIR = Path(__file__).resolve().parent.parent

# INPUT dans partie_2
INPUT = BASE_DIR.parent / "generation" / "reponses" / "reponses_llms.csv"
# OUTPUT dans partie_3
OUTPUT = BASE_DIR / "outputs" / "evaluations_scientifiques11.csv"

TOP_K = 6

# ‚úÖ BATCH
BATCH_START = 1
BATCH_END = 2

# ‚úÖ retry rate-limit
MAX_RETRIES = 5


def normalize_key(s: str) -> str:
    """Normalise un nom de colonne"""
    if s is None:
        return ""
    s = str(s).strip()
    s = s.replace("\ufeff", "")  # BOM UTF-8
    s = "".join(ch for ch in s if ch.isprintable())
    s = unicodedata.normalize("NFKD", s)
    s = "".join(ch for ch in s if not unicodedata.combining(ch))
    s = s.lower()
    s = re.sub(r"[^a-z0-9]+", "_", s).strip("_")
    return s


def detect_encoding(path: Path):
    """Essaie plusieurs encodings"""
    for enc in ("utf-8-sig", "utf-8", "cp1252", "latin-1"):
        try:
            with open(path, "r", encoding=enc, newline="") as f:
                f.readline()
            return enc
        except UnicodeDecodeError:
            continue
    return "utf-8"


def read_csv_with_excel(path: Path):
    """Lit le CSV en g√©rant le format Excel"""
    enc = detect_encoding(path)
    
    with open(path, "r", encoding=enc, newline="") as f:
        # D√©tecter le d√©limiteur
        sample = f.read(2048)
        f.seek(0)
        
        # Excel utilise souvent des tabulations ou des virgules
        if '\t' in sample:
            delimiter = '\t'
        elif ';' in sample:
            delimiter = ';'
        else:
            delimiter = ','
        
        reader = csv.DictReader(f, delimiter=delimiter)
        raw_fieldnames = reader.fieldnames or []
        
        print(f"üîç Colonnes d√©tect√©es: {raw_fieldnames}")
        print(f"üìÑ Encoding: {enc}, Delimiter: '{delimiter}'")
        
        # Cr√©er un mapping des colonnes
        col_map = {}
        for col in raw_fieldnames:
            norm = normalize_key(col)
            col_map[col] = norm
            print(f"   '{col}' -> '{norm}'")
        
        rows = []
        for r in reader:
            row_dict = {}
            for raw_col, value in r.items():
                norm_col = col_map.get(raw_col, normalize_key(raw_col))
                # Nettoyer la valeur
                if value:
                    value = str(value).strip()
                    # Enlever les \n litt√©raux
                    value = value.replace('\\n', '\n')
                row_dict[norm_col] = value
            rows.append(row_dict)
    
    print(f"‚úÖ {len(rows)} lignes lues")
    
    # Debug: afficher la premi√®re ligne
    if rows:
        print("\nüîç PREMI√àRE LIGNE:")
        for k, v in rows[0].items():
            display_val = v[:150] if v else '(vide)'
            print(f"   {k}: {display_val}")
    
    return rows


def pick(row: dict, *keys: str) -> str:
    """Retourne la premi√®re valeur non vide"""
    for k in keys:
        v = row.get(k, "")
        if not v:
            continue
        v = str(v).strip()
        if v and v.lower() not in ["nan", "none", "null", ""]:
            return v
    return ""


def build_evidence_text(evidence):
    blocks = []
    sources = []
    for e in evidence:
        src = e.get("source", "")
        path = e.get("path", "")
        chunk_id = e.get("chunk_id")
        score = float(e.get("score", 0.0))

        sources.append(f"{src}:{path}#chunk={chunk_id}")
        blocks.append(
            f"[{src}] {path} (chunk={chunk_id}, score={score:.4f})\n{e.get('text','')}"
        )
    return "\n\n---\n\n".join(blocks), " | ".join(sources)


def load_already_done():
    done = set()
    if not OUTPUT.exists():
        return done
    with open(OUTPUT, newline="", encoding="utf-8") as f:
        r = csv.DictReader(f)
        for row in r:
            done.add((row.get("id_cas", ""), row.get("modele", ""), row.get("sample_id", "")))
    print(f"‚úÖ {len(done)} √©valuations d√©j√† faites")
    return done


def call_judge_with_retry(prompt, response, evidence_text):
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            return judge_scientific(prompt, response, evidence_text)
        except Exception as e:
            msg = str(e)
            if "429" in msg or "Rate limit" in msg or "rate_limit" in msg:
                wait_s = min(60 * attempt, 300)
                print(f"‚ö†Ô∏è Rate limit. Attente {wait_s}s (retry {attempt}/{MAX_RETRIES})...")
                time.sleep(wait_s)
                continue
            raise
    raise RuntimeError("Trop de retries. R√©duisez le batch ou attendez.")


def run():
    if not INPUT.exists():
        raise FileNotFoundError(f"Fichier introuvable: {INPUT}")

    print("üöÄ Chargement RAG...")
    rag = get_rag()
    print("‚úÖ RAG charg√©\n")
    
    done = load_already_done()

    rows = read_csv_with_excel(INPUT)
    total = len(rows)

    out_fields = [
        "id_cas",
        "modele",
        "sample_id",
        "categorie_cas",
        "timestamp_reponse",
        "verdict_scientifique",
        "justification",
        "sources_utilisees",
        "topk",
        "batch_start",
        "batch_end",
        "timestamp_eval",
    ]

    file_exists = OUTPUT.exists()
    with open(OUTPUT, "a", newline="", encoding="utf-8") as f_out:
        writer = csv.DictWriter(f_out, fieldnames=out_fields, quoting=csv.QUOTE_ALL)
        if not file_exists:
            writer.writeheader()

        for i, row in enumerate(rows, start=1):
            if not (BATCH_START <= i <= BATCH_END):
                continue

            # ‚úÖ ORDRE CORRECT selon votre fichier
            # Colonnes: id_cas | categorie_cas | modele | sample_id | prompt | reponse_modele
            id_cas = pick(row, "id_cas", "idcas")
            categorie = pick(row, "categorie_cas", "categorie")
            modele = pick(row, "modele", "model")
            sample_id = pick(row, "sample_id", "sampleid")
            prompt = pick(row, "prompt", "question")
            response = pick(row, "reponse_modele", "reponse_model", "reponse")

            print(f"\n{'='*70}")
            print(f"üìù Ligne {i}/{total} (Batch {BATCH_START}-{BATCH_END})")
            print(f"   id_cas: '{id_cas}'")
            print(f"   categorie: '{categorie}'")
            print(f"   modele: '{modele}'")
            print(f"   sample_id: '{sample_id}'")
            print(f"   prompt: {prompt[:80] if prompt else '(VIDE)'}...")
            print(f"   response: {response[:80] if response else '(VIDE)'}...")

            key = (id_cas, modele, sample_id)
            if key in done and id_cas and modele and sample_id:
                print(f"‚Ü©Ô∏è D√©j√† √©valu√©, skip")
                continue

            # Cas r√©ponse vide
            if not response or not response.strip():
                writer.writerow({
                    "id_cas": id_cas,
                    "modele": modele,
                    "sample_id": sample_id,
                    "categorie_cas": categorie,
                    "timestamp_reponse": "",
                    "verdict_scientifique": "non_prouvee",
                    "justification": "R√©ponse vide: impossible d'√©valuer.",
                    "sources_utilisees": "",
                    "topk": str(TOP_K),
                    "batch_start": str(BATCH_START),
                    "batch_end": str(BATCH_END),
                    "timestamp_eval": datetime.now().isoformat(timespec="seconds"),
                })
                print(f"‚ö†Ô∏è R√©ponse vide => non_prouvee")
                continue

            # Construire la requ√™te RAG
            if prompt and prompt.strip():
                rag_query = f"{prompt}\n\n{response}"
            else:
                rag_query = response
            
            print(f"üîç Recherche RAG (top_k={TOP_K})...")
            try:
                evidence = rag.search(rag_query, top_k=TOP_K)
                evidence_text, sources_str = build_evidence_text(evidence)
                print(f"‚úÖ {len(evidence)} chunks trouv√©s")
            except Exception as e:
                print(f"‚ùå Erreur RAG: {e}")
                evidence_text = ""
                sources_str = ""

            # Appeler le juge
            print(f"‚öñÔ∏è √âvaluation par le juge...")
            try:
                raw = call_judge_with_retry(prompt, response, evidence_text)
                print(f"üìÑ R√©ponse brute: {raw[:150]}...")
            except Exception as e:
                print(f"‚ùå Erreur juge: {e}")
                raw = '{"verdict": "non_prouvee", "justification": "Erreur √©valuation"}'

            # Parser le JSON
            verdict = "non_prouvee"
            justification = ""
            try:
                obj = json.loads(raw)
                verdict = obj.get("verdict", "non_prouvee")
                justification = obj.get("justification", "")
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON invalide: {e}")
                justification = f"(JSON invalide) {raw[:300]}"

            # √âcrire le r√©sultat
            writer.writerow({
                "id_cas": id_cas,
                "modele": modele,
                "sample_id": sample_id,
                "categorie_cas": categorie,
                "timestamp_reponse": "",
                "verdict_scientifique": verdict,
                "justification": justification,
                "sources_utilisees": sources_str,
                "topk": str(TOP_K),
                "batch_start": str(BATCH_START),
                "batch_end": str(BATCH_END),
                "timestamp_eval": datetime.now().isoformat(timespec="seconds"),
            })
            f_out.flush()  # Forcer l'√©criture imm√©diate

            print(f"‚úÖ Verdict: {verdict}")
            print(f"   Justification: {justification[:100]}...")

    print("\n" + "="*70)
    print(f"‚úÖ TERMIN√â - Fichier: {OUTPUT}")


if __name__ == "__main__":
    run()